{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viterbi algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                0        1        2        3        4\n",
      "   clear  0.30000  0.03000  0.00900  0.00090  0.00009\n",
      "overcast  0.04000  0.01800  0.00270  0.00054  0.00020\n",
      "  cloudy  0.06000  0.04500  0.00450  0.00135  0.00020\n",
      "\n",
      "The observations are: dry drizzling dry drizzling rainy\n",
      "The most probable hidden path is: clear cloudy clear cloudy overcast\n"
     ]
    }
   ],
   "source": [
    "'''My Own Implementation!'''\n",
    "\n",
    "def viterbi(obs, states, start_pro, trans_pro, emit_pro):\n",
    "    # state sequence probability\n",
    "    seq_pro = [{}]\n",
    "\n",
    "    # start states probability (t = 0)\n",
    "    for state in states:\n",
    "        seq_pro[0][state] = start_pro[state] * emit_pro[state][obs[0]]\n",
    "\n",
    "    # transition states probatility (t > 0)\n",
    "    for t in range(1,len(obs)):\n",
    "        seq_pro.append({})\n",
    "        for next_state in states:\n",
    "            max_pro = max([seq_pro[t-1][cur_state] * trans_pro[cur_state][next_state] * emit_pro[next_state][obs[t]] for cur_state in states])\n",
    "            seq_pro[t][next_state] = max_pro\n",
    "    return seq_pro\n",
    "\n",
    "def table_creater(seq_pro):\n",
    "    '''Turn \"state sequence probability\" into \"Trellis diagram\".'''\n",
    "    print\n",
    "    print \" \" * 8,\n",
    "    for i in range(len(seq_pro)):\n",
    "        print \"%8d\" % i,\n",
    "    print\n",
    "\n",
    "    for state in seq_pro[0].keys():\n",
    "        print \"%8s\" % state,\n",
    "        for t in range(len(seq_pro)):\n",
    "            print \"%8.7s\" % (\"%f\" % seq_pro[t][state]),\n",
    "        print\n",
    "    print\n",
    "\n",
    "def path_finder(obs, seq_pro):\n",
    "    '''Find The most probable path.'''\n",
    "    path = []\n",
    "    for t in range(len(seq_pro)):\n",
    "        values = list(seq_pro[t].values())\n",
    "        keys = list(seq_pro[t].keys())\n",
    "        path.append(keys[values.index(max(values))])\n",
    "    print \"The observations are:\",\n",
    "    for i in obs:\n",
    "        print i,\n",
    "    print\n",
    "    print \"The most probable hidden path is:\",\n",
    "    for i in path:\n",
    "        print i,\n",
    "\n",
    "observations = ['dry', 'drizzling', 'dry', 'drizzling', 'rainy']\n",
    "total_states = ['clear', 'cloudy', 'overcast']\n",
    "start_probability = {'clear': 0.5, 'cloudy': 0.3, 'overcast': 0.2}\n",
    "trans_probability = {'clear': {'clear': 0.5, 'cloudy': 0.3, 'overcast': 0.2},\n",
    "                     'cloudy': {'clear': 0.2, 'cloudy': 0.5, 'overcast': 0.3},\n",
    "                     'overcast': {'clear': 0.2, 'cloudy': 0.3, 'overcast': 0.5}}\n",
    "emission_probability = {'clear': {'dry': 0.6, 'drizzling': 0.2, 'rainy': 0.2},\n",
    "                        'cloudy': {'dry': 0.2, 'drizzling': 0.5, 'rainy': 0.3},\n",
    "                        'overcast': {'dry': 0.2, 'drizzling': 0.3, 'rainy': 0.5}}\n",
    "\n",
    "V = viterbi(observations, total_states, start_probability, trans_probability, emission_probability)\n",
    "table_creater(V)\n",
    "path_finder(observations, V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('y', ['00', '11', '10', '00', '10', '00', '10', '11', '00', '11', '01', '01', '11', '11', '10', '00', '10', '00', '01', '01', '00', '01', '10', '01', '11', '11', '01', '10', '01', '11', '11', '01', '01', '00', '01', '01', '00', '01', '10', '10', '01', '00', '01', '10', '01', '11', '11', '10', '11', '11', '10', '11', '00', '11', '01', '01', '11', '11', '01', '01', '00', '01', '01', '11', '00', '11', '01', '01', '00', '01', '10', '10', '01', '00', '01', '10', '01', '00', '01', '10'])\n",
      "('z', ['00', '11', '10', '01', '10', '00', '10', '11', '10', '11', '01', '01', '11', '11', '10', '00', '10', '00', '01', '01', '00', '01', '10', '01', '11', '11', '01', '10', '01', '11', '11', '01', '01', '00', '01', '01', '00', '01', '10', '10', '01', '00', '01', '10', '01', '11', '10', '10', '11', '11', '10', '11', '00', '11', '01', '01', '11', '11', '01', '01', '00', '01', '01', '11', '00', '11', '01', '01', '00', '01', '10', '10', '01', '00', '01', '10', '00', '00', '01', '10'])\n",
      "['0', '1', '0', '1', '0', '1', '0', '0', '0', '1', '1', '0', '0', '1', '0', '1', '0', '1', '1', '0', '1', '1', '1', '0', '0', '1', '1', '1', '0', '0', '1', '1', '0', '1', '1', '0', '1', '1', '1', '1', '0', '1', '1', '1', '0', '0', '1', '0', '0', '1', '0', '0', '0', '1', '1', '0', '0', '1', '1', '0', '1', '1', '0', '0', '0', '1', '1', '0', '1', '1', '1', '1', '0', '1', '1', '1', '0', '1', '1', '1']\n",
      "('Decoded MSG:', u'TensorFlow')\n",
      "['', '', '', 'D', '', '', '', '', 'D', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', 'D', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', 'D', '', '', '']\n"
     ]
    }
   ],
   "source": [
    "#From open source http://stackoverflow.com/questions/7396849/convert-binary-to-ascii-and-vice-versa\n",
    "import binascii\n",
    "\n",
    "def text_to_bits(text, encoding='utf-8', errors='surrogatepass'):\n",
    "    bits = bin(int(binascii.hexlify(text.encode(encoding, errors)), 16))[2:]\n",
    "    return bits.zfill(8 * ((len(bits) + 7) // 8))\n",
    "\n",
    "def text_from_bits(bits, encoding='utf-8', errors='surrogatepass'):\n",
    "    n = int(bits, 2)\n",
    "    return int2bytes(n).decode(encoding, errors)\n",
    "\n",
    "def int2bytes(i):\n",
    "    hex_string = '%x' % i\n",
    "    n = len(hex_string)\n",
    "    return binascii.unhexlify(hex_string.zfill(n + (n & 1)))\n",
    "\n",
    "def viterbi_enc(fsm, s0, x):\n",
    "    y = []\n",
    "    ps = s0\n",
    "    for symbol in x:\n",
    "        y.append(fsm[ps][symbol]['out'])\n",
    "        ps = fsm[ps][symbol]['ns']\n",
    "    return y\n",
    "\n",
    "import random\n",
    "\n",
    "def add_noise(error_rate, x):\n",
    "    random.seed(10000)\n",
    "    y = []\n",
    "    for code in x:\n",
    "        new_code = ''\n",
    "        for b in code:\n",
    "            if random.random() < error_rate:\n",
    "                new_b = '0' if b =='1' else '1'\n",
    "            else:\n",
    "                new_b = b\n",
    "            new_code = new_code + new_b\n",
    "        y.append(new_code)\n",
    "    return y\n",
    "\n",
    "def ham_dist(a, b):\n",
    "    d = 0\n",
    "    for n in range(len(a)):\n",
    "        if a[n] != b[n]:\n",
    "            d += 1\n",
    "    return d\n",
    "\n",
    "def viterbi_dec(fsm_rev, s0, y):\n",
    "    dp_array = [{}]\n",
    "    path = {}\n",
    "    for s in fsm_rev.keys():\n",
    "        dp_array[0][s] = 0 if s ==s0 else 9999\n",
    "        path[s] = [s]\n",
    "    for i in range(len(y)):\n",
    "        dp_array.append({})\n",
    "        new_path = {}\n",
    "        for s in fsm_rev.keys():\n",
    "            min_dist = 999999\n",
    "            cur_dist = 999999\n",
    "            for s_prev in fsm_rev[s].keys():\n",
    "                dist = ham_dist(y[i], fsm_rev[s][s_prev]['out'])\n",
    "                cur_dist = dp_array[i][s_prev] + dist\n",
    "                if cur_dist < min_dist:\n",
    "                    min_dist = cur_dist\n",
    "                    min_state = s_prev\n",
    "            dp_array[i+1][s] = min_dist\n",
    "            new_path[s] = path[min_state] + [s]\n",
    "        path = new_path\n",
    "    best_dist, best_s = min((dp_array[-1][s], s) for s in dp_array[-1].keys())\n",
    "    best_p = path[best_s]\n",
    "    ml_code = []\n",
    "    ml_in = []\n",
    "    for i in range(len(best_p)-1, 0, -1):\n",
    "        ml_code = [fsm_rev[best_p[i]][best_p[i-1]]['out']] + ml_code\n",
    "        ml_in =   [fsm_rev[best_p[i]][best_p[i-1]]['in']] + ml_in\n",
    "    return ml_code, ml_in\n",
    "\n",
    "def viterbi_dec_limit_buff(fsm_rev, s0, buff_limit, y):\n",
    "    dp_array = [{}]\n",
    "    path = {}\n",
    "    ml = []\n",
    "    ml_in = []\n",
    "    for s in fsm_rev.keys():\n",
    "        dp_array[0][s] = 0 if s ==s0 else 9999\n",
    "        path[s] = [s]\n",
    "    for i in range(len(y)):\n",
    "        dp_array.append({})\n",
    "        new_path = {}\n",
    "        for s in fsm_rev.keys():\n",
    "            min_dist = 999999\n",
    "            cur_dist = 999999\n",
    "            for s_prev in fsm_rev[s].keys():\n",
    "                dist = ham_dist(y[i], fsm_rev[s][s_prev]['out'])\n",
    "                cur_dist = dp_array[-2][s_prev] + dist\n",
    "                if cur_dist < min_dist:\n",
    "                    min_dist = cur_dist\n",
    "                    min_state = s_prev\n",
    "            dp_array[-1][s] = min_dist\n",
    "            new_path[s] = path[min_state] + [s]\n",
    "        path = new_path\n",
    "        if (len(dp_array) > buff_limit):\n",
    "            best_dist, best_s = min((dp_array[-1][s], s) for s in dp_array[-1])\n",
    "            best_p = path[best_s]\n",
    "            ml += [fsm_rev[best_p[1]][best_p[0]]['out']]\n",
    "            ml_in += [fsm_rev[best_p[1]][best_p[0]]['in']]\n",
    "            dp_array.pop(0)\n",
    "            for p in path:\n",
    "                path[p].pop(0)\n",
    "        best_dist, best_s = min((dp_array[-1][s], s) for s in dp_array[-1])\n",
    "        best_p = path[best_s]   \n",
    "        for i in range(1, len(best_p)):\n",
    "            ml += [fsm_rev[best_p[i]][best_p[i-1]]['out']]\n",
    "            ml_in += [fsm_rev[best_p[i]][best_p[i-1]]['in']]\n",
    "    return dp_array, path, ml, ml_in\n",
    "\n",
    "fsm = {'a':{'0':{'ns':'a', 'out':'00'},\n",
    "            '1':{'ns':'b', 'out':'11'}},\n",
    "       'b':{'0':{'ns':'c', 'out':'10'},\n",
    "            '1':{'ns':'d', 'out':'01'}},\n",
    "       'c':{'0':{'ns':'a', 'out':'11'},\n",
    "            '1':{'ns':'b', 'out':'00'}},\n",
    "       'd':{'0':{'ns':'c', 'out':'01'},\n",
    "            '1':{'ns':'d', 'out':'10'}}}\n",
    "fsm_rev = {'a':{'a':{'in':'0', 'out':'00'},\n",
    "                'c':{'in':'0', 'out':'11'}},\n",
    "           'b':{'a':{'in':'1', 'out':'11'},\n",
    "                'c':{'in':'1', 'out':'00'}},\n",
    "           'c':{'b':{'in':'0', 'out':'10'},\n",
    "                'd':{'in':'0', 'out':'01'}},\n",
    "           'd':{'b':{'in':'1', 'out':'01'},\n",
    "                'd':{'in':'1', 'out':'10'}}}\n",
    "\n",
    "x = text_to_bits('TensorFlow')\n",
    "y = viterbi_enc(fsm,'a',x)\n",
    "print (\"y\", y)\n",
    "z = add_noise(.01, y)\n",
    "print (\"z\", z)\n",
    "mL_code, mL_in = viterbi_dec(fsm_rev, 'a', z)\n",
    "print(mL_in)\n",
    "dec_msg = text_from_bits(''.join(mL_in))\n",
    "print (\"Decoded MSG:\", dec_msg)\n",
    "print(['D' if a != b else '' for a,b in zip(z, mL_code)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pagerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from https://gist.github.com/diogojc/1338222\n",
    "import numpy as np\n",
    "from numpy.sparse import csc_matrix\n",
    "\n",
    "def pageRank(G, s = .85, maxerr = .001):\n",
    "    \"\"\"\n",
    "    Computes the pagerank for each of the n states.\n",
    "    Used in webpage ranking and text summarization using unweighted\n",
    "    or weighted transitions respectively.\n",
    "    Args\n",
    "    ----------\n",
    "    G: matrix representing state transitions\n",
    "       Gij can be a boolean or non negative real number representing the\n",
    "       transition weight from state i to j.\n",
    "    Kwargs\n",
    "    ----------\n",
    "    s: probability of following a transition. 1-s probability of teleporting\n",
    "       to another state. Defaults to 0.85\n",
    "    maxerr: if the sum of pageranks between iterations is bellow this we will\n",
    "            have converged. Defaults to 0.001\n",
    "    \"\"\"\n",
    "    n = G.shape[0]\n",
    "\n",
    "    # transform G into markov matrix M\n",
    "    M = csc_matrix(G,dtype=np.float)\n",
    "    rsums = np.array(M.sum(1))[:,0]\n",
    "    ri, ci = M.nonzero()\n",
    "    M.data /= rsums[ri]\n",
    "\n",
    "    # bool array of sink states\n",
    "    sink = rsums==0\n",
    "\n",
    "    # Compute pagerank r until we converge\n",
    "    ro, r = np.zeros(n), np.ones(n)\n",
    "    while np.sum(np.abs(r-ro)) > maxerr:\n",
    "        ro = r.copy()\n",
    "        # calculate each pagerank at a time\n",
    "        for i in xrange(0,n):\n",
    "            # inlinks of state i\n",
    "            Ii = np.array(M[:,i].todense())[:,0]\n",
    "            # account for sink states\n",
    "            Si = sink / float(n)\n",
    "            # account for teleportation to state i\n",
    "            Ti = np.ones(n) / float(n)\n",
    "\n",
    "            r[i] = ro.dot( Ii*s + Si*s + Ti*(1-s) )\n",
    "\n",
    "    # return normalized pagerank\n",
    "    return r/sum(r)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__=='__main__':\n",
    "    # Example extracted from 'Introduction to Information Retrieval'\n",
    "    G = np.array([[0,0,1,0,0,0,0],\n",
    "                  [0,1,1,0,0,0,0],\n",
    "                  [1,0,1,1,0,0,0],\n",
    "                  [0,0,0,1,1,0,0],\n",
    "                  [0,0,0,0,0,0,1],\n",
    "                  [0,0,0,0,0,1,1],\n",
    "                  [0,0,0,1,1,0,1]])\n",
    "\n",
    "    print pageRank(G,s=.86)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maximum Flow Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "# Ford–Fulkerson algorithm\n",
    "class Edge(object):\n",
    "    def __init__(self, u, v, w):\n",
    "        self.source = u\n",
    "        self.sink = v  \n",
    "        self.capacity = w\n",
    "    def __repr__(self):\n",
    "        return \"%s->%s:%s\" % (self.source, self.sink, self.capacity)\n",
    "\n",
    "class FlowNetwork(object):\n",
    "    def __init__(self):\n",
    "        self.adj = {}\n",
    "        self.flow = {}\n",
    " \n",
    "    def add_vertex(self, vertex):\n",
    "        self.adj[vertex] = []\n",
    " \n",
    "    def get_edges(self, v):\n",
    "        return self.adj[v]\n",
    " \n",
    "    def add_edge(self, u, v, w=0):\n",
    "        if u == v:\n",
    "            raise ValueError(\"u == v\")\n",
    "        edge = Edge(u,v,w)\n",
    "        redge = Edge(v,u,0)\n",
    "        edge.redge = redge\n",
    "        redge.redge = edge\n",
    "        self.adj[u].append(edge)\n",
    "        self.adj[v].append(redge)\n",
    "        self.flow[edge] = 0\n",
    "        self.flow[redge] = 0\n",
    " \n",
    "    def find_path(self, source, sink, path):\n",
    "        if source == sink:\n",
    "            return path\n",
    "        for edge in self.get_edges(source):\n",
    "            residual = edge.capacity - self.flow[edge]\n",
    "            if residual > 0 and edge not in path:\n",
    "                result = self.find_path( edge.sink, sink, path + [edge]) \n",
    "                if result != None:\n",
    "                    return result\n",
    " \n",
    "    def max_flow(self, source, sink):\n",
    "        path = self.find_path(source, sink, [])\n",
    "        while path != None:\n",
    "            residuals = [edge.capacity - self.flow[edge] for edge in path]\n",
    "            flow = min(residuals)\n",
    "            for edge in path:\n",
    "                self.flow[edge] += flow\n",
    "                self.flow[edge.redge] -= flow\n",
    "            path = self.find_path(source, sink, [])\n",
    "        return sum(self.flow[edge] for edge in self.get_edges(source))\n",
    "\n",
    "g = FlowNetwork()\n",
    "[g.add_vertex(v) for v in \"sopqrt\"]\n",
    "g.add_edge('s','o',3)\n",
    "g.add_edge('s','p',3)\n",
    "g.add_edge('o','p',2)\n",
    "g.add_edge('o','q',3)\n",
    "g.add_edge('p','r',2)\n",
    "g.add_edge('r','t',3)\n",
    "g.add_edge('q','r',4)\n",
    "g.add_edge('q','t',2)\n",
    "print (g.max_flow('s','t'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}